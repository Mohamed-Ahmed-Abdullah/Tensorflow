{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Components of the Model**\n",
    "\n",
    "* Model Function (cnn_model_fn)\n",
    "    * accept features, class labels, model and model parameters as args \n",
    "    * define the layers \n",
    "    * define a dictionary for the output of prediction \n",
    "    * create `EstimatorSpecs` object for the appropriate mode \n",
    "        * train, predict, evaluate \n",
    "        * create one-hot from class labeles for train and evaluate \n",
    "        * evaluate need dict of metrics to use \n",
    "        \n",
    "* Main Function \n",
    "    * accept model and model parameters as args \n",
    "    * call a function to get data \n",
    "        * load MNIST from TF in this case\n",
    "    * create the estimator with `cnn_model_fn` and model  parameters \n",
    "    * create `*_input_fn` where * is the mode (ex. train)\n",
    "        * use numpy_input_fn from the TF API for numpy data \n",
    "    * run the classifier/estimator using the appropriate mode \n",
    "    * perform any work nessesary to display or return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF, Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO) \n",
    "\n",
    "## Model Function \n",
    "def cnn_model_fn(features, labels, mode, params): \n",
    "    \"\"\"Model function for CNN.\"\"\" \n",
    "    # Input Layer \n",
    "    # Reshape X to 4-D telisor: (batch_size, width, height, channels) \n",
    "    # MNIST images are 28x28 pixels, and have one color channel \n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1]) # channels = 1 cause they are blacka and white if they are rgb then it will be 3\n",
    "    \n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation \n",
    "    # Input Tensor Shape: (batch_size, 28, 28, 1] \n",
    "    # Output Tensor Shape: (batch_size, 28, 28, 32]  #it's the same 28, 28 cause we are using padding same , 32 is the filter\n",
    "    conv1 = tf.layers.conv2d( \n",
    "                inputs=input_layer, \n",
    "                filters=32, \n",
    "                kernel_size=[5, 5], #our filter size\n",
    "                padding=\"same\", # use \"valid\" to not preserve WxH \n",
    "                activation=tf.nn.relu) \n",
    "    \n",
    "    # First max pooling layer with a 2x2 filter and stride of 2 \n",
    "    #stride determin if we have an overlap or not we can make it skip as well but thats not a normal thing to do\n",
    "    #if the stride is the same as the filter width insures that there is no overlap \n",
    "    # Input Tensor Shape: (batch_size, 28, 28, 32) \n",
    "    # Output Tensor Shape: (batch_size, 14, 14, 32) \n",
    "    pooll = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2) \n",
    "    \n",
    "    # Computes 64 feature maps using a 5x5 filter. \n",
    "    # Input Tensor Shape: (batch_size, 14, 14, 32) \n",
    "    # Output Tensor Shape: (batch_size, 14, 14, 64)\n",
    "    conv2 = tf.layers.conv2d( \n",
    "                inputs=pooll, \n",
    "                filters=64, \n",
    "                kernel_size=[5, 51], \n",
    "                padding=\"same\", \n",
    "                activation=tf.nn.relu) \n",
    "    \n",
    "    # Input Tensor Shape: (batch_size, 14, 14, 64) \n",
    "    # Output Tensor Shape: (batch_size, 7, 7, 64] \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2) \n",
    "\n",
    "    # Flatten tensor into a batch of vectors for input to dense layer \n",
    "    # -1 -> for the batch \n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64]) \n",
    "    \n",
    "    # Input Tensor Shape: (batch_size, 7 * 7 * 64] \n",
    "    # Output Tensor Shape: (batch_size, 1024] \n",
    "    # units = nodes  \n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu) \n",
    "    \n",
    "    # Add dropout operation; 0.6 probability that element will be kept \n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN) \n",
    "    \n",
    "    # Logits layer \n",
    "    # Input Tensor Shape: (batch_size, 1024) \n",
    "    # Output Tensor Shape: (batch_size, 10)\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10) \n",
    "    \n",
    "    # this dict will be returned for predictions \n",
    "    predictions={ \n",
    "        # actual class predictions \n",
    "        \"classes\": tf.argmax(input=logits, axis=1), \n",
    "        # class probabilities from softmax on logits \n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\") \n",
    "    } \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT: \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions) \n",
    "    \n",
    "    # Calculate loss (for both TRAIN and EVAL modes) \n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10) \n",
    "    loss = tf.losses.softmax_cross_entropy( onehot_labels=onehot_labels, logits=logits) \n",
    "    \n",
    "    # Configure the training Op (for TRAIN mode) \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN: \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001) \n",
    "        train_op = optimizer.minimize( loss=loss, global_step=tf.train.get_global_step()) \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op) \n",
    "    \n",
    "    # evaluation metrics (for EVAL mode) \n",
    "    eval_metric_ops = { \n",
    "        \"accuracy\": tf.metrics.accuracy( \n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec( \n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops) \n",
    "\n",
    "\n",
    "## Main Function \n",
    "def main(mode='train', model_params={'learning_rate': 0.001}): \n",
    "    # Load training and eval data \n",
    "    mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\") \n",
    "    train_data = mnist.train.images # Returns np.array \n",
    "    train_labels = np.asarray(mnist.train.labels, dtype=np.int32) \n",
    "    eval_data = mnist.test.images # Returns np.array \n",
    "    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32) \n",
    "    \n",
    "    #Create the Estimator \n",
    "    mnist_classifier = tf.estimator.Estimator( \n",
    "        model_fn=cnn_model_fn, params=model_params, model_dir=\"/tmp/mnist_convnet_model\") \n",
    "    \n",
    "    # Train the model \n",
    "    if mode == 'train': \n",
    "        train_input_fn = tf.estimator.inputs.numpy_input_fn( \n",
    "            x={\"x\": train_data}, \n",
    "            y=train_labels, \n",
    "            batch_size=100, \n",
    "            num_epochs=10, \n",
    "            shuffle=True) \n",
    "        mnist_classifier.train( \n",
    "            input_fn=train_input_fn) \n",
    "    elif mode == 'predict': \n",
    "        predict_input_fn = tf.estimator.inputs.numpy_input_fn( \n",
    "            x={\"x\": eval_data}, \n",
    "            num_epochs=1, \n",
    "            shuffle=False) \n",
    "        preds = mnist_classifier.predict( \n",
    "            input_fn=predict_input_fn) \n",
    "        return np.array([p for p in preds]) \n",
    "    elif mode == 'eval': \n",
    "        #Evaluate the model and print results \n",
    "        eval_input_fn = tf.estimator.inputs.numpy_input_fn( \n",
    "            x={\"x\": eval_data}, \n",
    "            y=eval_labels, \n",
    "            num_epochs=1, \n",
    "            shuffle=False) \n",
    "        eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn) \n",
    "        print(eval_results) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000008F8026D828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3045797, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.01338\n",
      "INFO:tensorflow:loss = 2.2981346, step = 101 (98.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.995122\n",
      "INFO:tensorflow:loss = 2.275647, step = 201 (100.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.987314\n",
      "INFO:tensorflow:loss = 2.2566912, step = 301 (101.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.982754\n",
      "INFO:tensorflow:loss = 2.244992, step = 401 (101.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.967443\n",
      "INFO:tensorflow:loss = 2.22776, step = 501 (103.357 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 595 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.984577\n",
      "INFO:tensorflow:loss = 2.1940165, step = 601 (101.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.914926\n",
      "INFO:tensorflow:loss = 2.1722975, step = 701 (109.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.946325\n",
      "INFO:tensorflow:loss = 2.1088521, step = 801 (105.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.941262\n",
      "INFO:tensorflow:loss = 2.063746, step = 901 (106.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.966376\n",
      "INFO:tensorflow:loss = 1.9914796, step = 1001 (103.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.946146\n",
      "INFO:tensorflow:loss = 1.9053626, step = 1101 (105.615 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1162 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.953504\n",
      "INFO:tensorflow:loss = 1.8358301, step = 1201 (104.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.946065\n",
      "INFO:tensorflow:loss = 1.6747656, step = 1301 (105.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.958838\n",
      "INFO:tensorflow:loss = 1.3706317, step = 1401 (104.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.948355\n",
      "INFO:tensorflow:loss = 1.3441356, step = 1501 (105.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.961522\n",
      "INFO:tensorflow:loss = 1.1645678, step = 1601 (103.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.968624\n",
      "INFO:tensorflow:loss = 1.0503434, step = 1701 (103.246 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1736 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.959666\n",
      "INFO:tensorflow:loss = 0.9256244, step = 1801 (104.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.959665\n",
      "INFO:tensorflow:loss = 0.7380133, step = 1901 (104.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.963246\n",
      "INFO:tensorflow:loss = 0.7741234, step = 2001 (103.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.930629\n",
      "INFO:tensorflow:loss = 0.8649475, step = 2101 (107.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.96823\n",
      "INFO:tensorflow:loss = 0.681075, step = 2201 (103.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.946236\n",
      "INFO:tensorflow:loss = 0.47123012, step = 2301 (105.689 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2308 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.940336\n",
      "INFO:tensorflow:loss = 0.6584036, step = 2401 (106.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.929789\n",
      "INFO:tensorflow:loss = 0.5468301, step = 2501 (107.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.906707\n",
      "INFO:tensorflow:loss = 0.5436684, step = 2601 (110.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.856665\n",
      "INFO:tensorflow:loss = 0.4867521, step = 2701 (116.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.857908\n",
      "INFO:tensorflow:loss = 0.41878116, step = 2801 (116.556 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2850 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.953689\n",
      "INFO:tensorflow:loss = 0.32887006, step = 2901 (104.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.979668\n",
      "INFO:tensorflow:loss = 0.50927466, step = 3001 (102.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.984543\n",
      "INFO:tensorflow:loss = 0.31877133, step = 3101 (101.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.88992\n",
      "INFO:tensorflow:loss = 0.41773126, step = 3201 (112.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.884571\n",
      "INFO:tensorflow:loss = 0.5520012, step = 3301 (113.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.902979\n",
      "INFO:tensorflow:loss = 0.47012115, step = 3401 (110.754 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3407 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.866595\n",
      "INFO:tensorflow:loss = 0.4531471, step = 3501 (115.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.913571\n",
      "INFO:tensorflow:loss = 0.33818874, step = 3601 (109.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.944072\n",
      "INFO:tensorflow:loss = 0.45049706, step = 3701 (105.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.948193\n",
      "INFO:tensorflow:loss = 0.31352928, step = 3801 (105.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.925492\n",
      "INFO:tensorflow:loss = 0.26992974, step = 3901 (108.042 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3962 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.950909\n",
      "INFO:tensorflow:loss = 0.41135007, step = 4001 (105.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.950167\n",
      "INFO:tensorflow:loss = 0.36496064, step = 4101 (105.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.929541\n",
      "INFO:tensorflow:loss = 0.32954925, step = 4201 (107.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.907432\n",
      "INFO:tensorflow:loss = 0.3286689, step = 4301 (110.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.908752\n",
      "INFO:tensorflow:loss = 0.33683562, step = 4401 (110.030 sec)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
